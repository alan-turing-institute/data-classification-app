# Ethics Application for the Information Governance Collaboration

## I. BACKGROUND INFORMATION AND SCOPING

### Is The Alan Turing Institute the lead institution for this research?
- This is a Turing 2.0 proposal with UCL as the lead partner, we believe the Turing research ethics committee is the correct body in this instance.
-	**Yes - continue completing the form**
-	No - you do not need an EAG approval but an approval from your university’s ethics body

###  Are you the principal investigator/research lead?
-	Yes - James Hetherington (Turing Institute and UCL is PI)
-	No - Be prepared to say who is and add their email address

### Which Turing programme does this project fall under?
Tools, Practices & Systems

### 1. Project Goal and Purpose
*Please introduce your project. Tell us, among other things:
- the purpose and goal of your project
- the intended benefits of your project
- how this research project aligns with the Turing's goals, challenges, and/or objectives*

---
The purpose of the Turing’s information governance app is to bring stakeholders with diverse perspectives on data protection – investigators, data protection experts, and other researchers – to assess datasets and arrive at a sensitivity classification for the data and the technical recommendations for the protections needed. This project is looking to make the app implementable at other institutions and organisations as an open source tool.

This project is building towards an open-source version of the Turing Information Governance app that can be deployed by other research organisations to support their data management and trustworthy research environment infrastructure. We're preparing this release through a combination of technical work, user testing, and a deep understanding of the existing information governance processes and needs at different institutions. It also aims to provide a record of decision-making around information governance and data protection to comply with audit requirements. In the first phase, funded by Turing 2.0, the project team are seeking to set up the potential deployment of the app across the Turing, UCL, and Cambridge.

---

### 2. Data and Research Methods Description
*Please provide a description / overview of the data that you will use for your project, if any, as well as the research methods you will use.
Please cover:
- the type of data
- the amount of data in the sample, e.g. number of people, items, variables, months, years covered in the data
- the sources of the data, e.g. the datasets that will be used, who they were created by, where they are accessible from
- if known, where and how the data to be used was collected
- a brief description of the research to be carried out and the methods that will be used*

This project will not make direct use of any sensitive and/or confidential data, addressing exemplar sensitive datasets only for the purpose of evaluating our novel information governance tools. The app is designed to provide a framework to obtain a resilient and evidenced data security classification. The participants in our user studies will be focused on the metadata of projects that they know (which may encompass sensitive data) but not the data itself. For instance: project title, and answers to yes/no questions such as 'will the project input be personal data', 'is that personal data pseudonymised' etc. The app will store this information, in order to process a security tier evaluation. As such, ethics and governance risks are minimal. At no point are sensitive datasets examined, let alone stored or processed.

We will make some use of sensitive data already entrusted to the participating domain co-investigators, but only to test and evaluate the information governance app.
The resulting classifications are for evaluation purposes only and will not change how the data is handled for the research projects it is part of.
If, at any point during testing, data is re-identified, the exercise will halt and domain co-investigator alerted.

We will not be carrying out novel analysis as part of the work, and all controls already in place around this data will remain in place.
For avoidance of any doubt, in these cases, we will request confirmation from each data provider that they are content with consideration of data and metadata for evaluation of future information governance approaches, and, if not, we will for that domain, consider only generic 'typical data in the field' rather than evaluating the particular dataset.

We will be conducting approximately 20 interviews and user experience testing sessions with prospective users of this app. Their roles will range from project management staff to principal investigators to information governance professionals from UCL, Cambridge and Turing. During these sessions we have a number of scenarios we wish our prospective users to conduct using the app, and we will be noting their experiences, feedback and areas for improvement from them.

### Has your study received funding from the Department of Health (for Social Care Research) or the Ministry of Defence?
-	Yes – DH: liaise with EAG and be ready to share approval received from relevant body
-	Yes – MoD: liaise with EAG and be ready to share approval received from relevant body
-	**No - go to next step**

### Does your study involve NHS staff, patients, facilities, premises or data? Is your project research involving prisoners or adults lacking capacity, a clinical trial of a medicinal product or does it relate to human tissue (even if outside the NHS)?
-	Yes - liaise with EAG and be ready to share approval received from relevant body
-	**No - go to next step**

### Is your research a consulting task for a client? If so, you will not need an ethics review (but you will still need to finish and submit this form).
*Does your study meet all of the following conditions?
•	The research is on behalf of or at the request of an institution or company.
•	The research aims primarily to monitor or improve the performance of that institution.
•	Conclusions of the research will be wholly applicable to that institution.
•	Conclusions of the research, nor the data used will NOT be published.*

-	Yes - Submit form as is
-	**No - go to next step**

## II. Please answer the questions in the following section which will enable the EAG to assess the ethical implication of your research.
### Consent: 3. Please comment on any issues around securing consent raised by your research.
*Where you identify risks, you should inform us how your research plans to minimise or eliminate them.*

Questions to consider:
- If your study involves collecting data about, with, or from human participants, will they receive all relevant information about what their participation will involve, prior to providing consent?
- If your study involves using existing data about people, was their consent given for the original data collection? Did they consent to this data being reused?

**Answer:** We will make some use of knowledge of the attributes of sensitive data already entrusted to the participating domain co-investigators, but only to test and evaluate the information governance app.
The resulting classifications are for evaluation purposes only and will not change how the data is handled for the research projects it is part of.

We will not be carrying out novel analysis as part of the work, and all controls already in place around this data will remain in place.
For avoidance of any doubt, in these cases, we will request confirmation from each data provider that they are content with consideration of data and metadata for evaluation of future information governance approaches, and, if not, we will for that domain, consider only generic 'typical data in the field' rather than evaluating the particular dataset.

We will collect data from a range of users about app functionality and design. 
This will involve recording the personal data required to link feedback to individuals for further follow up, but we will acquire explicit consent for this and keep the personal information collected to the minimum required (name and email address). The consent form we share with users providing details on what data we gather and how we use it is attached.
We will complete the Turing's data protection assessment process for this data.


### Privacy and Security: 4. Please comment on any issues of privacy and security raised by your research.
*Where you identify risks, you should inform us how your research plans to minimise or eliminate them.*

Questions to consider:
- If you use data about people in your study, is this data anonymous, or anonymised? Could it be associated with identifiable individuals, including by triangulating with other publicly available datasets?
- How do you plan to keep sensitive data safe and secure? What will you do with sensitive data after the study is completed?

**Answer:** This is a research project about how, in general, best to provide this kind of security.
However, we will not, within this project, be using real data in manners that might result in any additional exposure risk over current practices.

The web app (see Q2 on extent of data) will be used during the interviews and will be hosted by each participating institution (Turing, UCL, Cambridge) on their secure, managed and supported computing infrastructure. With user consent, video recordings will be taken of the sessions to facilitate retrospective note-taking, and will be deleted once notes have been assembled. The notes from each interview will the gathered using HackMD (collaborative online note taking app) and transferred to the project's private GitHub wiki once the final edits have been made.

### Other Harms: 5. Please comment on the potential for individual, societal or ecological harms to arise from your research, beyond what is described above.
*Where you identify risks, you should inform us how your research plans to minimise or eliminate them.*

Questions to consider:
- Could any harms arise to the people involved in conducting this research (e.g. viewing violent content could harm researchers)?
- Could conducting or promoting this research create unintended negative outcomes, such as environmental damage, new power imbalances, or the misuse of technology?
- How do you plan to ascertain and acknowledge the limitations of your research, if any (e.g. does the data sample you use allow for generalisability of your research findings)?
-  What benefits could your research contribute that would balance or outweigh any potentially negative impacts that could arise?

**Answer:** None expected. The purpose of this work is to develop a research prototype in order to generate insight and understanding, which we will openly publish.

However, there are potential implications if the research prototype developed here is adopted for real production use without due reivew.
Therefore, we undertake for our own institutions not to move into production without a proper ethics and governance review.
In our (open) publications of research outputs from this work, we will highlight that institutions making use of the conclusions of this research must apply appropriate governance and ethics process.


## III. FINAL DECLARATIONS
#### In light of the risks that you have identified in this application, do you think the level of safeguards you have implemented in your research plan sufficiently mitigate ethical risks?
- **Yes**
- No

#### In light of the risks you have identified and the level of detail about the project that you have provided in this application, do you think reviewers have sufficient information to judge whether your planned project offers sufficient safeguards?
- **Yes**
- No
