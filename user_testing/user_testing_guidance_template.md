# Guidance for Turing app UX testing observers - May 2022

This is the template for user testing sessions.

**NOTE**: please copy the markdown into a new file to capture the raw data


## Setup

### Details
To share with the user:
* [URL](https://dca.dsgroupdev.co.uk/)
* [User introduction](https://hackmd.io/CZ07HWEISQ6kx2lyiVesRA?view)
* User credentials:
    * **Username**: `authelia`
    * **Password**: Stored in Keybase

### Attendance
It's good to have two attendees minimum, one to facilitate the session with the user and one to take notes. Please note that if the user declines to have the session recorded, comprehensive notes will have to be taken to record as much information as possible.

    
## Facilitator notes

### Session structure

Before starting the testing session, run through the following points with the user:

1. Ethics approval
    * [Ethics approval form](https://hackmd.io/bBcyMwPsT3qj_uHkwro72A?both)
    * Clarify that they are happy for the session to be recorded, and for us to take notes
2. Highlight that we are testing the *app*, not the user - anything that isn't clear/they struggle with is on us not them!
    * Encourage them to think aloud as much as possible, even if they feel unsure - this helps us clarify their experience and learn about exactly what needs to change about the app. 
    * We may also ask questions during the session to tease out some of these ideas
3. Explain how the session will run
    * They will first have a chance to read through the user introduction, and we will then pause for feedback
    * Introduce the situation - they are an investigator for a number of dummy projects, and they will need to:
        1. Choose a project to work on
        2. Assign a dataset to the project
        3. Assign users roles on the work package associated with the dataset
        4. Run a classification process on the work package
    * At the end we'll pause for general thoughts and feedback

### Managing the testing session

The user has four steps to complete within the session. They should initally just be told what they are trying to do, e.g. 'Your first task is to choose a project to work on', and then given time to try and figure it out for themselves. A couple of things to think about:

* Try not to direct the user _at all_, even if they're not going the right way. We want to see how they use the app without supervision! Only step in if a) they are unable to make any more progress, b) a path they are on may lead to the app breaking or c) to clarify bad instructions
* As they progress through each step, remind them to think aloud. A good way to tease this out is with open ended questions, e.g. 'what are you thinking?', 'why did you click there?', 'what does that mean to you?'
* Once they reach the end of the step, pause and gather feedback.
    * Try to ask only open ended questions, and avoid putting ideas in their heads (e.g. questions like 'did you like the colour of the button?').
        * One specific question to ask is 'what (if anything) did they find confusing?'
    * Make sure we get negative as well as positive feedback
    * Treat it like a conversation - explore possible solutions, ask for clarification, explain how things work...
* Finally, get a score out of 10 from the user for how they rate going through this step.
* Once we're happy that all feedback has been gathered, move on to the next step

## Note taking

Please take notes for each step below. Include both what happened, and direct quotes from the user. 

If comfortable, the note-taker can also fill out the [analysis]() notes at the same time. However, recording user thought and what happens is more important.

1. Read through the user guide
 * Duration (m):
 * Tester UX score:
 * Confusing:
 * Comments:

2. Select a project at random from the list of pre-defined dummy projects
  * Duration (m):
  * Tester UX score:
  * Comments:
  * Confusing:

3. Assign a new (dummy) dataset to a project (tester to create metadata, encouraged to make it similar to the real-life data they are currently working on). Assume that the data provider representative associated with the dataset is called Crystal Bowers, and her details have already been added to the app
  * Duration (m):
  * Tester UX score:
  * Comments: 
  * Confusing:
  
4. Assign random selection of users from pre-defined list of users to other roles in chosen project
  * Duration (m):
  * Tester UX score:
  * Comments:
  * Confusing:

5. Run through classification of “Ingress” work package
  * Duration (m):
  * Tester UX score:
  * Comments:
  * Confusing: 

Finally, go back through the questions that appeared while the tester was working through the classification task and assess how relevant each was to their own situation, and whether there was a clear answer in each case.

